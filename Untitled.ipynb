{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8941c36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "%matplotlib inline\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b66aca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cols = ['attempts_date_created', 'cl_date_assignment', 'cls_date_created']\n",
    "df = pd.read_csv('wide_math.csv', parse_dates=date_cols, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8627fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['attempts_date_created'] = df['attempts_date_created'].dt.floor('s')\n",
    "# df['cls_date_created'] = df['cls_date_created'].dt.floor('s')\n",
    "# df.drop(['Unnamed: 0.1', 'Unnamed: 0'], axis=1).to_csv('wide_math.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6a1614c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>assignment_level</th>\n",
       "      <th>attempts_date_created</th>\n",
       "      <th>cl_date_assignment</th>\n",
       "      <th>cl_id</th>\n",
       "      <th>cls_date_created</th>\n",
       "      <th>cls_student_id</th>\n",
       "      <th>course_id</th>\n",
       "      <th>is_solved</th>\n",
       "      <th>problem_id</th>\n",
       "      <th>subject_slug</th>\n",
       "      <th>team_id</th>\n",
       "      <th>team_level</th>\n",
       "      <th>tp_teacher_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-03-08 11:02:37+03:00</td>\n",
       "      <td>2022-03-05 13:00:00+03:00</td>\n",
       "      <td>71374307</td>\n",
       "      <td>2022-03-08 10:52:43+03:00</td>\n",
       "      <td>1650006</td>\n",
       "      <td>5096626</td>\n",
       "      <td>1</td>\n",
       "      <td>97304</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>82516</td>\n",
       "      <td>4</td>\n",
       "      <td>520541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-03-08 11:02:49+03:00</td>\n",
       "      <td>2021-09-02 14:23:50+03:00</td>\n",
       "      <td>70879797</td>\n",
       "      <td>2022-03-08 11:02:08+03:00</td>\n",
       "      <td>1494142</td>\n",
       "      <td>5099807</td>\n",
       "      <td>1</td>\n",
       "      <td>227546</td>\n",
       "      <td>mathematics</td>\n",
       "      <td>69290</td>\n",
       "      <td>4</td>\n",
       "      <td>615530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  assignment_level     attempts_date_created  \\\n",
       "0             0           0                 3 2022-03-08 11:02:37+03:00   \n",
       "1             1           1                 3 2022-03-08 11:02:49+03:00   \n",
       "\n",
       "         cl_date_assignment     cl_id          cls_date_created  \\\n",
       "0 2022-03-05 13:00:00+03:00  71374307 2022-03-08 10:52:43+03:00   \n",
       "1 2021-09-02 14:23:50+03:00  70879797 2022-03-08 11:02:08+03:00   \n",
       "\n",
       "   cls_student_id  course_id  is_solved  problem_id subject_slug  team_id  \\\n",
       "0         1650006    5096626          1       97304  mathematics    82516   \n",
       "1         1494142    5099807          1      227546  mathematics    69290   \n",
       "\n",
       "   team_level  tp_teacher_id  \n",
       "0           4         520541  \n",
       "1           4         615530  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497afb02",
   "metadata": {},
   "source": [
    "- assignment_level - класс, когда он решал\n",
    "- attempts_date_created - время поптыки\n",
    "- cl_date_assigment - время выдачи задачи\n",
    "- cl-id - id урока, который выдан студентам этого класса. урок - набор карточек, который выдал учитель.\n",
    "- cls_date_created - когда приступил к уроку\n",
    "- cls_student_id - id ученика\n",
    "- course_id - id курса (предмет-учитель-assignment_level)\n",
    "- is_solved - решена ли задача\n",
    "- problem-id - id задачи\n",
    "- subject_slug - предмет\n",
    "- team-id - id класса\n",
    "- team_level - текущик класс ученика\n",
    "- tp_teacher_id - id препода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94cd06cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark_up_math = pd.read_excel('markup_math.xlsx')\n",
    "# mark_up_math= mark_up_math[1:]\n",
    "# mark_up_math.head(4) # очень грязные данные(((("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a894d00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "med_date = df['attempts_date_created'].median()\n",
    "med_user = df['cls_student_id'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a83d3525",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_df = df[df['attempts_date_created'] > med_date]\n",
    "before_df = df[df['attempts_date_created'] <= med_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a175be25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.357354172481161"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(post_df['problem_id']).difference(before_df['problem_id'])) / len(set(post_df['problem_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bb24d5",
   "metadata": {},
   "source": [
    "Если отсекать по датасет по времени, то есть куча задач, про которые мы не знаем, так как нет информации прошлых лет их решения. Предлагаю делить датасет по времени и пользователям и взять 1/4 от датасета для валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44a184e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = (df['cls_student_id'] > med_user) & (df['attempts_date_created'] > med_date)\n",
    "train_index = ~test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb318e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matr(data):\n",
    "    data = data.sort_values(by=['problem_id', 'cls_student_id', 'attempts_date_created'])\n",
    "    return data.groupby(by=['problem_id', 'cls_student_id'], as_index=False)['is_solved'].first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "467bb6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3003185, 3)\n",
      "(1005800, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>problem_id</th>\n",
       "      <th>cls_student_id</th>\n",
       "      <th>is_solved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>1550166</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>1550167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000</td>\n",
       "      <td>1550169</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   problem_id  cls_student_id  is_solved\n",
       "0       20000         1550166          0\n",
       "1       20000         1550167          1\n",
       "2       20000         1550169          1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = get_matr(df[train_index])\n",
    "df_test = get_matr(df[test_index])\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbbddf1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7478247260824757, 0.7262736130443428)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['is_solved'].sum() / df_train.shape[0], df_test['is_solved'].sum() / df_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272b5741",
   "metadata": {},
   "source": [
    "Есть разбаланс классов. Ученики чаще решают с первого раза, чем не решают."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3edabd27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1368838357393971"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_problems = set(df_train['problem_id'])\n",
    "test_problems = set(df_test['problem_id'])\n",
    "\n",
    "\n",
    "len(test_problems.difference(train_problems)) / len(test_problems)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43f7ae3",
   "metadata": {},
   "source": [
    "У нас ещё осталось 13% задач в тестовой выборке, про которые мы ничего не знаем\n",
    "Пока есть предложение на них забить. Тем более это логично забить на задачи, про которые нам ещё ничего не известно.\n",
    "(в дальнейшем есть идея для них эмбединги получать из графа)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92df47b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0297008547008547"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_students = set(df_train['cls_student_id'])\n",
    "test_students = set(df_test['cls_student_id'])\n",
    "\n",
    "len(test_students.difference(train_students)) / len(test_students)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8d1090",
   "metadata": {},
   "source": [
    "Есть 3 процента пользователей, которые не попали в тестовую выборку. Пока что от них тоже избавимся. У меня есть идеи, как более качественно поделить выборку, но пока напишем базу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1e45ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943531, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_test[df_test['problem_id'].apply(lambda x: x in train_problems)]\n",
    "df_test = df_test[df_test['cls_student_id'].apply(lambda x: x in train_students)]\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3576ea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = list(train_problems)\n",
    "problem_to_index = {problem_id: i for i, problem_id in enumerate(problems)}\n",
    "students = list(train_students)\n",
    "student_to_index = {student_id: i for i, student_id in enumerate(students)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55373cd3",
   "metadata": {},
   "source": [
    "Теперь напишем стандарные штуки для обучения (сворую из другого курса)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "226f7d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentsProblemsDataset(Dataset):\n",
    "    def __init__(self, data, student_to_index=student_to_index, problem_to_index=problem_to_index):\n",
    "        students = data['cls_student_id'].apply(lambda x:student_to_index[x]).values\n",
    "        problems = data['problem_id'].apply(lambda x:problem_to_index[x]).values\n",
    "        \n",
    "        self.students = torch.tensor(students)\n",
    "        self.problems = torch.tensor(problems)\n",
    "        self.solved = torch.tensor(data['is_solved'].to_numpy())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.students)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.students[idx], self.problems[idx], self.solved[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2b7a735",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = StudentsProblemsDataset(df_train)\n",
    "test_dataset = StudentsProblemsDataset(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c42d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1306d867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TP(y_pred, y_true, target=1):\n",
    "    return ((y_pred == target) * (y_true == target)).sum()\n",
    "\n",
    "def get_FP(y_pred, y_true, target=1):\n",
    "    return ((y_pred == target) * (y_true != target)).sum()\n",
    "\n",
    "def get_FN(y_pred, y_true, target=1):\n",
    "    return ((y_pred != target) * (y_true != target)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4ed171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision(y_pred, y_true, target=1):\n",
    "    TP = get_TP(y_pred, y_true)\n",
    "    FP = get_FP(y_pred, y_true)\n",
    "    \n",
    "    return TP / (TP + FP)\n",
    "\n",
    "def get_recall(y_pred, y_true, target=1):\n",
    "    TP = get_TP(y_pred, y_true)\n",
    "    FN = get_FN(y_pred, y_true)\n",
    "    \n",
    "    return TP / (TP + FN)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader, criterion, target=1, device=DEVICE):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    loss = 0\n",
    "    \n",
    "    for st, pr, y_true in dataloader:\n",
    "        st = st.to(DEVICE)\n",
    "        pr = pr.to(DEVICE)\n",
    "        y_true = y_true.to(DEVICE)\n",
    "        \n",
    "        y_pred= model(st, pr)\n",
    "        \n",
    "        loss += criterion(y_pred, y_true).item()\n",
    "        \n",
    "        y_pred = torch.argmin(y_pred, dim=1)\n",
    "        \n",
    "        TP += get_TP(y_pred, y_true, target)\n",
    "        FP += get_FP(y_pred, y_true, target)\n",
    "        FN += get_FN(y_pred, y_true, target)\n",
    "    \n",
    "    precision = (TP / (TP + FP)).item()\n",
    "    recall = (TP / (TP + FN)).item()\n",
    "    return loss, precision, recall\n",
    "\n",
    "def plot_results(train_loss, test_loss, train_precision, test_precision, train_recall, test_recall):\n",
    "    clear_output(True)\n",
    "    \n",
    "    print(f\"Cur test loss:{test_loss[-1]:.3}\")\n",
    "    print(f\"Cur test precision:{test_precision[-1]:.3}\")\n",
    "    print(f\"Cur test recall:{test_recall[-1]:.3}\")\n",
    "    \n",
    "    x = list(range(len(train_loss)))\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.title('loss')\n",
    "    plt.plot(x, train_loss, label='train')\n",
    "    plt.plot(x, test_loss, label='test')\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.title('precison')\n",
    "    plt.plot(x, train_precision, label='train')    \n",
    "    plt.plot(x, test_precision, label='test')\n",
    "    plt.ylim((0, 1))\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(3, 1, 3)    \n",
    "    plt.plot(x, train_recall, label='train')\n",
    "    plt.plot(x, test_recall, label='test')\n",
    "    plt.ylim((0, 1))\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73c38e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KindOfAlsModel(nn.Module):\n",
    "    def __init__(self, n_students=len(students), n_problems=len(problems), emb_size=16):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.stud_embed = nn.Embedding(n_students, emb_size)\n",
    "        self.problem_embed = nn.Embedding(n_problems, emb_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, students, problems):\n",
    "        students = self.stud_embed(students)\n",
    "        problems = self.problem_embed(problems)\n",
    "        \n",
    "        solved = self.tanh(torch.mul(students, problems).sum(dim=1)) / 2 + 0.5\n",
    "        not_solved = 1 - solved\n",
    "        return torch.stack([1-solved, solved]).transpose(-2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5635887",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, n_students=len(students), n_problems=len(problems), emb_size=16):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.stud_embed = nn.Embedding(n_students, emb_size)\n",
    "        self.problem_embed = nn.Embedding(n_problems, emb_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, students, problems):\n",
    "        students = self.stud_embed(students)\n",
    "        problems = self.problem_embed(problems)\n",
    "        \n",
    "        solved = self.tanh(torch.mul(students, problems).sum(dim=1)) / 2 + 0.5\n",
    "        not_solved = 1 - solved\n",
    "        return torch.stack([1-solved, solved]).transpose(-2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01c28527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3lkrasdo) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "912ce40111d04fa7a13cc0f78223a6da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.004 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.148880…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">dry-puddle-10</strong>: <a href=\"https://wandb.ai/ysda-project/ysda-school-simple-als/runs/3lkrasdo\" target=\"_blank\">https://wandb.ai/ysda-project/ysda-school-simple-als/runs/3lkrasdo</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221025_173412-3lkrasdo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3lkrasdo). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20a3ad5d1454970ad88fe0511e6d2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668314083411438, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/aba/progger/project_shad/wandb/run-20221025_173514-2x2fmurj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/ysda-project/ysda-school-simple-als/runs/2x2fmurj\" target=\"_blank\">mild-flower-11</a></strong> to <a href=\"https://wandb.ai/ysda-project/ysda-school-simple-als\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = KindOfAlsModel().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "wandb.init(project=\"ysda-school-simple-als\")\n",
    "\n",
    "\n",
    "batch_size=20000\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=12)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4040a3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818a93f629804c2da698aa09cb8f6128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_every = 5\n",
    "epochs = 200\n",
    "\n",
    "wandb.config = {\n",
    "  \"learning_rate\": 0.001,\n",
    "  \"epochs\": epochs,\n",
    "  \"batch_size\": batch_size,\n",
    "}\n",
    "\n",
    "\n",
    "for epoch in trange(epochs):\n",
    "    for st, pr, target in train_dataloader:\n",
    "        st = st.to(DEVICE)\n",
    "        pr = pr.to(DEVICE)\n",
    "        target = target.to(DEVICE)\n",
    "        \n",
    "        y_pred= model(st, pr)\n",
    "        \n",
    "        loss = criterion(y_pred, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (epoch + 1) % eval_every == 0:\n",
    "        train_loss, train_precision, train_recall = evaluate(model, train_dataloader, criterion, target=1)\n",
    "        test_loss, test_precision, test_precision = evaluate(model, test_dataloader, criterion, target=1)\n",
    "        \n",
    "        wandb.log({\"train/train_loss\": train_loss})\n",
    "        wandb.log({\"train/train_precision_t1\": train_precision})\n",
    "        wandb.log({\"train/train_recall_t1\": train_recall})\n",
    "        wandb.log({\"test/test_loss_t1\": train_loss})\n",
    "        wandb.log({\"test/test_precision_t1\": test_precision})\n",
    "        wandb.log({\"test/test_recall_t1\": test_precision})\n",
    "        \n",
    "        _, train_precision, train_recall = evaluate(model, train_dataloader, criterion, target=0)\n",
    "        _, test_precision, test_precision = evaluate(model, test_dataloader, criterion, target=0)\n",
    "        \n",
    "        wandb.log({\"train/train_precision_t0\": train_precision})\n",
    "        wandb.log({\"train/train_recall_t0\": train_recall})\n",
    "        wandb.log({\"test/test_precision_t0\": test_precision})\n",
    "        wandb.log({\"test/test_recall_t0\": test_precision})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73d1bd58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2x2fmurj) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a02fdfec7e439d83875c43dafc1f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.005 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.133438…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test/test_loss_t1</td><td>██▇▇▆▆▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test/test_precision_t0</td><td>▁▁▁▁▁▂▂▃▃▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>test/test_precision_t1</td><td>█████▇▇▆▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test/test_recall_t0</td><td>▁▁▁▁▁▂▂▃▃▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>test/test_recall_t1</td><td>█████▇▇▆▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/train_loss</td><td>██▇▇▆▆▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/train_precision_t0</td><td>█▇▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/train_precision_t1</td><td>██▇▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/train_recall_t0</td><td>▁▁▁▁▁▂▂▃▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>train/train_recall_t1</td><td>█████▇▇▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test/test_loss_t1</td><td>67.83061</td></tr><tr><td>test/test_precision_t0</td><td>0.50297</td></tr><tr><td>test/test_precision_t1</td><td>0.49703</td></tr><tr><td>test/test_recall_t0</td><td>0.50297</td></tr><tr><td>test/test_recall_t1</td><td>0.49703</td></tr><tr><td>train/train_loss</td><td>67.83061</td></tr><tr><td>train/train_precision_t0</td><td>0.10837</td></tr><tr><td>train/train_precision_t1</td><td>0.20819</td></tr><tr><td>train/train_recall_t0</td><td>0.66141</td></tr><tr><td>train/train_recall_t1</td><td>0.33859</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">mild-flower-11</strong>: <a href=\"https://wandb.ai/ysda-project/ysda-school-simple-als/runs/2x2fmurj\" target=\"_blank\">https://wandb.ai/ysda-project/ysda-school-simple-als/runs/2x2fmurj</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221025_173514-2x2fmurj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2x2fmurj). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2313920460374b2f8702b0fae92cc946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669041416510783, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/aba/progger/project_shad/wandb/run-20221025_180616-3dd8qd0x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/ysda-project/ysda-school-emb-lin/runs/3dd8qd0x\" target=\"_blank\">confused-star-2</a></strong> to <a href=\"https://wandb.ai/ysda-project/ysda-school-emb-lin\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = KindOfAlsModel().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "wandb.init(project=\"ysda-school-emb-lin\")\n",
    "\n",
    "batch_size=20000\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=12)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8cde79fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8638dc4bbb2848b8ba260d817115f688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_every = 5\n",
    "epochs = 200\n",
    "\n",
    "wandb.config = {\n",
    "  \"learning_rate\": 0.001,\n",
    "  \"epochs\": epochs,\n",
    "  \"batch_size\": batch_size,\n",
    "}\n",
    "\n",
    "\n",
    "for epoch in trange(epochs):\n",
    "    for st, pr, target in train_dataloader:\n",
    "        st = st.to(DEVICE)\n",
    "        pr = pr.to(DEVICE)\n",
    "        target = target.to(DEVICE)\n",
    "        \n",
    "        y_pred= model(st, pr)\n",
    "        \n",
    "        loss = criterion(y_pred, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (epoch + 1) % eval_every == 0:\n",
    "        train_loss, train_precision, train_recall = evaluate(model, train_dataloader, criterion)\n",
    "        test_loss, test_precision, test_precision = evaluate(model, test_dataloader, criterion)\n",
    "        \n",
    "        wandb.log({\"train/train_loss\": train_loss})\n",
    "        wandb.log({\"train/train_precision_t1\": train_precision})\n",
    "        wandb.log({\"train/train_recall_t1\": train_recall})\n",
    "        wandb.log({\"test/test_loss_t1\": train_loss})\n",
    "        wandb.log({\"test/test_precision_t1\": test_precision})\n",
    "        wandb.log({\"test/test_recall_t1\": test_precision})\n",
    "        \n",
    "        _, train_precision, train_recall = evaluate(model, train_dataloader, criterion, target=0)\n",
    "        _, test_precision, test_precision = evaluate(model, test_dataloader, criterion, target=0)\n",
    "        \n",
    "        wandb.log({\"train/train_precision_t0\": train_precision})\n",
    "        wandb.log({\"train/train_recall_t0\": train_recall})\n",
    "        wandb.log({\"test/test_precision_t0\": test_precision})\n",
    "        wandb.log({\"test/test_recall_t0\": test_precision})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
